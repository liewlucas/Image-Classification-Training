TRAINING MODEL....
Number of Batches per Epoch: 338
Epoch 1/5
Batch: 1, Loss: 0.7110
Batch: 2, Loss: 0.6588
Batch: 3, Loss: 0.5717
Batch: 4, Loss: 0.5300
Batch: 5, Loss: 0.5166
Batch: 6, Loss: 0.4663
Batch: 7, Loss: 0.4099
Batch: 8, Loss: 0.3862
Batch: 9, Loss: 0.3627
Batch: 10, Loss: 0.3568
Batch: 11, Loss: 0.3307
Batch: 12, Loss: 0.3156
Batch: 13, Loss: 0.2886
Batch: 14, Loss: 0.2935
Batch: 15, Loss: 0.2832
Batch: 16, Loss: 0.2658
Batch: 17, Loss: 0.2962
Batch: 18, Loss: 0.2471
Batch: 19, Loss: 0.2604
Batch: 20, Loss: 0.2201
Batch: 21, Loss: 0.2213
Batch: 22, Loss: 0.2280
Batch: 23, Loss: 0.2625
Batch: 24, Loss: 0.2377
Batch: 25, Loss: 0.2355
Batch: 26, Loss: 0.2305
Batch: 27, Loss: 0.2397
Batch: 28, Loss: 0.2332
Batch: 29, Loss: 0.1994
Batch: 30, Loss: 0.2263
Batch: 31, Loss: 0.2343
Batch: 32, Loss: 0.2526
Batch: 33, Loss: 0.2245
Batch: 34, Loss: 0.2208
Batch: 35, Loss: 0.2594
Batch: 36, Loss: 0.2161
Batch: 37, Loss: 0.2097
Batch: 38, Loss: 0.1961
Batch: 39, Loss: 0.1888
Batch: 40, Loss: 0.2150
Batch: 41, Loss: 0.1986
Batch: 42, Loss: 0.1931
Batch: 43, Loss: 0.2255
Batch: 44, Loss: 0.1892
Batch: 45, Loss: 0.2032
Batch: 46, Loss: 0.2124
Batch: 47, Loss: 0.2145
Batch: 48, Loss: 0.2136
Batch: 49, Loss: 0.2229
Batch: 50, Loss: 0.2006
Batch: 51, Loss: 0.1875
Batch: 52, Loss: 0.2179
Batch: 53, Loss: 0.2246
Batch: 54, Loss: 0.2361
Batch: 55, Loss: 0.1763
Batch: 56, Loss: 0.2004
Batch: 57, Loss: 0.1979
Batch: 58, Loss: 0.2156
Batch: 59, Loss: 0.1705
Batch: 60, Loss: 0.1720
Batch: 61, Loss: 0.1742
Batch: 62, Loss: 0.2104
Batch: 63, Loss: 0.2272
Batch: 64, Loss: 0.1767
Batch: 65, Loss: 0.2006
Batch: 66, Loss: 0.1803
Batch: 67, Loss: 0.1968
Batch: 68, Loss: 0.1879
Batch: 69, Loss: 0.2121
Batch: 70, Loss: 0.1977
Batch: 71, Loss: 0.1910
Batch: 72, Loss: 0.1855
Batch: 73, Loss: 0.1786
Batch: 74, Loss: 0.1783
Batch: 75, Loss: 0.1641
Batch: 76, Loss: 0.1696
Batch: 77, Loss: 0.1881
Batch: 78, Loss: 0.1705
Batch: 79, Loss: 0.1891
Batch: 80, Loss: 0.2066
Batch: 81, Loss: 0.1776
Batch: 82, Loss: 0.1514
Batch: 83, Loss: 0.1883
Batch: 84, Loss: 0.2116
Batch: 85, Loss: 0.1937
Batch: 86, Loss: 0.1669
Batch: 87, Loss: 0.1520
Batch: 88, Loss: 0.1844
Batch: 89, Loss: 0.2468
Batch: 90, Loss: 0.1693
Batch: 91, Loss: 0.2222
Batch: 92, Loss: 0.1716
Batch: 93, Loss: 0.1811
Batch: 94, Loss: 0.2050
Batch: 95, Loss: 0.1768
Batch: 96, Loss: 0.1664
Batch: 97, Loss: 0.2229
Batch: 98, Loss: 0.1996
Batch: 99, Loss: 0.1770
Batch: 100, Loss: 0.1427
Batch: 101, Loss: 0.1650
Batch: 102, Loss: 0.1818
Batch: 103, Loss: 0.1929
Batch: 104, Loss: 0.1714
Batch: 105, Loss: 0.1757
Batch: 106, Loss: 0.1618
Batch: 107, Loss: 0.1703
Batch: 108, Loss: 0.1801
Batch: 109, Loss: 0.1913
Batch: 110, Loss: 0.1766
Batch: 111, Loss: 0.1994
Batch: 112, Loss: 0.1836
Batch: 113, Loss: 0.1676
Batch: 114, Loss: 0.1588
Batch: 115, Loss: 0.1501
Batch: 116, Loss: 0.1996
Batch: 117, Loss: 0.1781
Batch: 118, Loss: 0.2047
Batch: 119, Loss: 0.1920
Batch: 120, Loss: 0.2050
Batch: 121, Loss: 0.2008
Batch: 122, Loss: 0.1765
Batch: 123, Loss: 0.1635
Batch: 124, Loss: 0.1907
Batch: 125, Loss: 0.1603
Batch: 126, Loss: 0.2155
Batch: 127, Loss: 0.2024
Batch: 128, Loss: 0.1846
Batch: 129, Loss: 0.2061
Batch: 130, Loss: 0.2085
Batch: 131, Loss: 0.2219
Batch: 132, Loss: 0.1667
Batch: 133, Loss: 0.2275
Batch: 134, Loss: 0.2287
Batch: 135, Loss: 0.1903
Batch: 136, Loss: 0.2140
Batch: 137, Loss: 0.1844
Batch: 138, Loss: 0.1941
Batch: 139, Loss: 0.2093
Batch: 140, Loss: 0.1951
Batch: 141, Loss: 0.1911
Batch: 142, Loss: 0.1551
Batch: 143, Loss: 0.2142
Batch: 144, Loss: 0.2199
Batch: 145, Loss: 0.1985
Batch: 146, Loss: 0.1592
Batch: 147, Loss: 0.1988
Batch: 148, Loss: 0.2081
Batch: 149, Loss: 0.1797
Batch: 150, Loss: 0.1775
Batch: 151, Loss: 0.1747
Batch: 152, Loss: 0.2073
Batch: 153, Loss: 0.1851
Batch: 154, Loss: 0.1440
Batch: 155, Loss: 0.1660
Batch: 156, Loss: 0.2342
Batch: 157, Loss: 0.1831
Batch: 158, Loss: 0.1897
Batch: 159, Loss: 0.1450
Batch: 160, Loss: 0.1591
Batch: 161, Loss: 0.1617
Batch: 162, Loss: 0.1678
Batch: 163, Loss: 0.1719
Batch: 164, Loss: 0.2064
Batch: 165, Loss: 0.1716
Batch: 166, Loss: 0.1649
Batch: 167, Loss: 0.1596
Batch: 168, Loss: 0.1684
Batch: 169, Loss: 0.1686
Batch: 170, Loss: 0.1776
Batch: 171, Loss: 0.2021
Batch: 172, Loss: 0.1787
Batch: 173, Loss: 0.2032
Batch: 174, Loss: 0.1835
Batch: 175, Loss: 0.1564
Batch: 176, Loss: 0.1745
Batch: 177, Loss: 0.1596
Batch: 178, Loss: 0.1625
Batch: 179, Loss: 0.1809
Batch: 180, Loss: 0.1649
Batch: 181, Loss: 0.1401
Batch: 182, Loss: 0.1892
Batch: 183, Loss: 0.1569
Batch: 184, Loss: 0.1442
Batch: 185, Loss: 0.1330
Batch: 186, Loss: 0.1611
Batch: 187, Loss: 0.1824
Batch: 188, Loss: 0.1510
Batch: 189, Loss: 0.1723
Batch: 190, Loss: 0.1762
Batch: 191, Loss: 0.1626
Batch: 192, Loss: 0.1926
Batch: 193, Loss: 0.1623
Batch: 194, Loss: 0.2179
Batch: 195, Loss: 0.1576
Batch: 196, Loss: 0.1688
Batch: 197, Loss: 0.1645
Batch: 198, Loss: 0.1621
Batch: 199, Loss: 0.1805
Batch: 200, Loss: 0.1813
Batch: 201, Loss: 0.1750
Batch: 202, Loss: 0.1695
Batch: 203, Loss: 0.1665
Batch: 204, Loss: 0.1614
Batch: 205, Loss: 0.1719
Batch: 206, Loss: 0.1983
Batch: 207, Loss: 0.1801
Batch: 208, Loss: 0.1617
Batch: 209, Loss: 0.1476
Batch: 210, Loss: 0.1814
Batch: 211, Loss: 0.1885
Batch: 212, Loss: 0.1486
Batch: 213, Loss: 0.2001
Batch: 214, Loss: 0.1662
Batch: 215, Loss: 0.1875
Batch: 216, Loss: 0.2049
Batch: 217, Loss: 0.1934
Batch: 218, Loss: 0.1768
Batch: 219, Loss: 0.1959
Batch: 220, Loss: 0.2343
Batch: 221, Loss: 0.2084
Batch: 222, Loss: 0.1512
Batch: 223, Loss: 0.1855
Batch: 224, Loss: 0.1690
Batch: 225, Loss: 0.1767
Batch: 226, Loss: 0.1459
Batch: 227, Loss: 0.1956
Batch: 228, Loss: 0.1819
Batch: 229, Loss: 0.1605
Batch: 230, Loss: 0.1535
Batch: 231, Loss: 0.1643
Batch: 232, Loss: 0.1871
Batch: 233, Loss: 0.2009
Batch: 234, Loss: 0.1954
Batch: 235, Loss: 0.1604
Batch: 236, Loss: 0.1756
Batch: 237, Loss: 0.1672
Batch: 238, Loss: 0.1602
Batch: 239, Loss: 0.1730
Batch: 240, Loss: 0.1600
Batch: 241, Loss: 0.1652
Batch: 242, Loss: 0.1279
Batch: 243, Loss: 0.1695
Batch: 244, Loss: 0.1113
Batch: 245, Loss: 0.1522
Batch: 246, Loss: 0.1579
Batch: 247, Loss: 0.1464
Batch: 248, Loss: 0.1370
Batch: 249, Loss: 0.1711
Batch: 250, Loss: 0.1752
Batch: 251, Loss: 0.1909
Batch: 252, Loss: 0.1758
Batch: 253, Loss: 0.1711
Batch: 254, Loss: 0.1628
Batch: 255, Loss: 0.1788
Batch: 256, Loss: 0.1659
Batch: 257, Loss: 0.1375
Batch: 258, Loss: 0.1557
Batch: 259, Loss: 0.1354
Batch: 260, Loss: 0.1794
Batch: 261, Loss: 0.1241
Batch: 262, Loss: 0.1615
Batch: 263, Loss: 0.1354
Batch: 264, Loss: 0.2171
Batch: 265, Loss: 0.1984
Batch: 266, Loss: 0.1535
Batch: 267, Loss: 0.1509
Batch: 268, Loss: 0.1869
Batch: 269, Loss: 0.1613
Batch: 270, Loss: 0.2060
Batch: 271, Loss: 0.1420
Batch: 272, Loss: 0.1980
Batch: 273, Loss: 0.1466
Batch: 274, Loss: 0.1659
Batch: 275, Loss: 0.1038
Batch: 276, Loss: 0.2063
Batch: 277, Loss: 0.2091
Batch: 278, Loss: 0.1364
Batch: 279, Loss: 0.1768
Batch: 280, Loss: 0.1886
Batch: 281, Loss: 0.1389
Batch: 282, Loss: 0.1571
Batch: 283, Loss: 0.1716
Batch: 284, Loss: 0.1571
Batch: 285, Loss: 0.1835
Batch: 286, Loss: 0.1726
Batch: 287, Loss: 0.1341
Batch: 288, Loss: 0.1945
Batch: 289, Loss: 0.1545
Batch: 290, Loss: 0.1634
Batch: 291, Loss: 0.1743
Batch: 292, Loss: 0.1252
Batch: 293, Loss: 0.2247
Batch: 294, Loss: 0.1429
Batch: 295, Loss: 0.1538
Batch: 296, Loss: 0.1625
Batch: 297, Loss: 0.1805
Batch: 298, Loss: 0.1702
Batch: 299, Loss: 0.1244
Batch: 300, Loss: 0.1783
Batch: 301, Loss: 0.1985
Batch: 302, Loss: 0.1650
Batch: 303, Loss: 0.1876
Batch: 304, Loss: 0.2101
Batch: 305, Loss: 0.2219
Batch: 306, Loss: 0.1558
Batch: 307, Loss: 0.1547
Batch: 308, Loss: 0.1355
Batch: 309, Loss: 0.1952
Batch: 310, Loss: 0.1742
Batch: 311, Loss: 0.1694
Batch: 312, Loss: 0.1747
Batch: 313, Loss: 0.1453
Batch: 314, Loss: 0.1428
Batch: 315, Loss: 0.1402
Batch: 316, Loss: 0.1660
Batch: 317, Loss: 0.1470
Batch: 318, Loss: 0.2530
Batch: 319, Loss: 0.1598
Batch: 320, Loss: 0.1579
Batch: 321, Loss: 0.1512
Batch: 322, Loss: 0.2043
Batch: 323, Loss: 0.1747
Batch: 324, Loss: 0.1793
Batch: 325, Loss: 0.1794
Batch: 326, Loss: 0.1669
Batch: 327, Loss: 0.1834
Batch: 328, Loss: 0.1451
Batch: 329, Loss: 0.1782
Batch: 330, Loss: 0.1886
Batch: 331, Loss: 0.1847
Batch: 332, Loss: 0.1498
Batch: 333, Loss: 0.1637
Batch: 334, Loss: 0.1387
Batch: 335, Loss: 0.1838
Batch: 336, Loss: 0.1525
Batch: 337, Loss: 0.1770
Batch: 338, Loss: 0.1756
Epoch 1/5 - Training Loss: 0.1934
Epoch 1/5, Train Loss: 0.1934, Validation Loss: 0.1438
Epoch 2/5
Batch: 1, Loss: 0.1222
Batch: 2, Loss: 0.3301
Batch: 3, Loss: 0.1791
Batch: 4, Loss: 0.2731
Batch: 5, Loss: 0.2329
Batch: 6, Loss: 0.1758
Batch: 7, Loss: 0.1755
Batch: 8, Loss: 0.2343
Batch: 9, Loss: 0.1953
Batch: 10, Loss: 0.1847
Batch: 11, Loss: 0.1792
Batch: 12, Loss: 0.1960
Batch: 13, Loss: 0.2102
Batch: 14, Loss: 0.1706
Batch: 15, Loss: 0.1890
Batch: 16, Loss: 0.1801
Batch: 17, Loss: 0.1996
Batch: 18, Loss: 0.1860
Batch: 19, Loss: 0.1747
Batch: 20, Loss: 0.1968
Batch: 21, Loss: 0.2227
Batch: 22, Loss: 0.1739
Batch: 23, Loss: 0.1744
Batch: 24, Loss: 0.1517
Batch: 25, Loss: 0.2253
Batch: 26, Loss: 0.1816
Batch: 27, Loss: 0.1977
Batch: 28, Loss: 0.1623
Batch: 29, Loss: 0.1759
Batch: 30, Loss: 0.2314
Batch: 31, Loss: 0.1588
Batch: 32, Loss: 0.1661
Batch: 33, Loss: 0.2080
Batch: 34, Loss: 0.2049
Batch: 35, Loss: 0.1988
Batch: 36, Loss: 0.2136
Batch: 37, Loss: 0.1664
Batch: 38, Loss: 0.1561
Batch: 39, Loss: 0.2615
Batch: 40, Loss: 0.1776
Batch: 41, Loss: 0.1800
Batch: 42, Loss: 0.1480
Batch: 43, Loss: 0.1735
Batch: 44, Loss: 0.1847
Batch: 45, Loss: 0.1674
Batch: 46, Loss: 0.1757
Batch: 47, Loss: 0.1987
Batch: 48, Loss: 0.1902
Batch: 49, Loss: 0.2068
Batch: 50, Loss: 0.1867
Batch: 51, Loss: 0.2108
Batch: 52, Loss: 0.2279
Batch: 53, Loss: 0.2182
Batch: 54, Loss: 0.1975
Batch: 55, Loss: 0.2154
Batch: 56, Loss: 0.1606
Batch: 57, Loss: 0.2102
Batch: 58, Loss: 0.1837
Batch: 59, Loss: 0.2105
Batch: 60, Loss: 0.2042
Batch: 61, Loss: 0.1927
Batch: 62, Loss: 0.2189
Batch: 63, Loss: 0.1929
Batch: 64, Loss: 0.2052
Batch: 65, Loss: 0.1895
Batch: 66, Loss: 0.1602
Batch: 67, Loss: 0.2045
Batch: 68, Loss: 0.1968
Batch: 69, Loss: 0.1773
Batch: 70, Loss: 0.1930
Batch: 71, Loss: 0.1716
Batch: 72, Loss: 0.2090
Batch: 73, Loss: 0.2032
Batch: 74, Loss: 0.1832
Batch: 75, Loss: 0.1975
Batch: 76, Loss: 0.1960
Batch: 77, Loss: 0.1917
Batch: 78, Loss: 0.1829
Batch: 79, Loss: 0.2056
Batch: 80, Loss: 0.1843
Batch: 81, Loss: 0.1662
Batch: 82, Loss: 0.2043
Batch: 83, Loss: 0.1844
Batch: 84, Loss: 0.2011
Batch: 85, Loss: 0.1760
Batch: 86, Loss: 0.1842
Batch: 87, Loss: 0.1516
Batch: 88, Loss: 0.1765
Batch: 89, Loss: 0.2000
Batch: 90, Loss: 0.1773
Batch: 91, Loss: 0.1754
Batch: 92, Loss: 0.2069
Batch: 93, Loss: 0.2200
Batch: 94, Loss: 0.1589
Batch: 95, Loss: 0.1415
Batch: 96, Loss: 0.1504
Batch: 97, Loss: 0.2184
Batch: 98, Loss: 0.1769
Batch: 99, Loss: 0.1345
Batch: 100, Loss: 0.2129
Batch: 101, Loss: 0.1578
Batch: 102, Loss: 0.1308
Batch: 103, Loss: 0.1651
Batch: 104, Loss: 0.1855
Batch: 105, Loss: 0.1546
Batch: 106, Loss: 0.1632
Batch: 107, Loss: 0.1626
Batch: 108, Loss: 0.1414
Batch: 109, Loss: 0.2204
Batch: 110, Loss: 0.1819
Batch: 111, Loss: 0.1944
Batch: 112, Loss: 0.2431
Batch: 113, Loss: 0.2300
Batch: 114, Loss: 0.1417
Batch: 115, Loss: 0.2018
Batch: 116, Loss: 0.1543
Batch: 117, Loss: 0.1633
Batch: 118, Loss: 0.1568
Batch: 119, Loss: 0.1687
Batch: 120, Loss: 0.1817
Batch: 121, Loss: 0.1925
Batch: 122, Loss: 0.1932
Batch: 123, Loss: 0.1727
Batch: 124, Loss: 0.1903
Batch: 125, Loss: 0.1716
Batch: 126, Loss: 0.2312
Batch: 127, Loss: 0.1827
Batch: 128, Loss: 0.1856
Batch: 129, Loss: 0.1809
Batch: 130, Loss: 0.1750
Batch: 131, Loss: 0.2094
Batch: 132, Loss: 0.1350
Batch: 133, Loss: 0.1563
Batch: 134, Loss: 0.1843
Batch: 135, Loss: 0.1660
Batch: 136, Loss: 0.1494
Batch: 137, Loss: 0.1782
Batch: 138, Loss: 0.1379
Batch: 139, Loss: 0.1877
Batch: 140, Loss: 0.1995
Batch: 141, Loss: 0.1492
Batch: 142, Loss: 0.1528
Batch: 143, Loss: 0.1769
Batch: 144, Loss: 0.1939
Batch: 145, Loss: 0.1819
Batch: 146, Loss: 0.2009
Batch: 147, Loss: 0.1278
Batch: 148, Loss: 0.1777
Batch: 149, Loss: 0.1660
Batch: 150, Loss: 0.1318
Batch: 151, Loss: 0.1752
Batch: 152, Loss: 0.1502
Batch: 153, Loss: 0.1705
Batch: 154, Loss: 0.1778
Batch: 155, Loss: 0.2043
Batch: 156, Loss: 0.1478
Batch: 157, Loss: 0.1426
Batch: 158, Loss: 0.1434
Batch: 159, Loss: 0.1827
Batch: 160, Loss: 0.1720
Batch: 161, Loss: 0.1730
Batch: 162, Loss: 0.1445
Batch: 163, Loss: 0.1643
Batch: 164, Loss: 0.1177
Batch: 165, Loss: 0.1513
Batch: 166, Loss: 0.1606
Batch: 167, Loss: 0.1898
Batch: 168, Loss: 0.1600
Batch: 169, Loss: 0.1934
Batch: 170, Loss: 0.2410
Batch: 171, Loss: 0.2189
Batch: 172, Loss: 0.1883
Batch: 173, Loss: 0.1748
Batch: 174, Loss: 0.1893
Batch: 175, Loss: 0.1258
Batch: 176, Loss: 0.1599
Batch: 177, Loss: 0.2557
Batch: 178, Loss: 0.2230
Batch: 179, Loss: 0.1891
Batch: 180, Loss: 0.1527
Batch: 181, Loss: 0.1301
Batch: 182, Loss: 0.1735
Batch: 183, Loss: 0.2203
Batch: 184, Loss: 0.1515
Batch: 185, Loss: 0.1706
Batch: 186, Loss: 0.1570
Batch: 187, Loss: 0.1404
Batch: 188, Loss: 0.1386
Batch: 189, Loss: 0.1851
Batch: 190, Loss: 0.1841
Batch: 191, Loss: 0.1789
Batch: 192, Loss: 0.1710
Batch: 193, Loss: 0.1952
Batch: 194, Loss: 0.1778
Batch: 195, Loss: 0.1657
Batch: 196, Loss: 0.1787
Batch: 197, Loss: 0.1778
Batch: 198, Loss: 0.1587
Batch: 199, Loss: 0.1775
Batch: 200, Loss: 0.1837
Batch: 201, Loss: 0.2215
Batch: 202, Loss: 0.1654
Batch: 203, Loss: 0.1882
Batch: 204, Loss: 0.2231
Batch: 205, Loss: 0.1828
Batch: 206, Loss: 0.1930
Batch: 207, Loss: 0.1682
Batch: 208, Loss: 0.1911
Batch: 209, Loss: 0.1695
Batch: 210, Loss: 0.2195
Batch: 211, Loss: 0.1417
Batch: 212, Loss: 0.2234
Batch: 213, Loss: 0.1586
Batch: 214, Loss: 0.2007
Batch: 215, Loss: 0.1860
Batch: 216, Loss: 0.2073
Batch: 217, Loss: 0.1940
Batch: 218, Loss: 0.1789
Batch: 219, Loss: 0.1665
Batch: 220, Loss: 0.1777
Batch: 221, Loss: 0.1365
Batch: 222, Loss: 0.1553
Batch: 223, Loss: 0.1708
Batch: 224, Loss: 0.1891
Batch: 225, Loss: 0.1766
Batch: 226, Loss: 0.1526
Batch: 227, Loss: 0.1694
Batch: 228, Loss: 0.1790
Batch: 229, Loss: 0.1569
Batch: 230, Loss: 0.1652
Batch: 231, Loss: 0.1440
Batch: 232, Loss: 0.1848
Batch: 233, Loss: 0.1775
Batch: 234, Loss: 0.1762
Batch: 235, Loss: 0.1655
Batch: 236, Loss: 0.1570
Batch: 237, Loss: 0.1947
Batch: 238, Loss: 0.1683
Batch: 239, Loss: 0.1513
Batch: 240, Loss: 0.1685
Batch: 241, Loss: 0.1492
Batch: 242, Loss: 0.2609
Batch: 243, Loss: 0.1662
Batch: 244, Loss: 0.1332
Batch: 245, Loss: 0.1768
Batch: 246, Loss: 0.1612
Batch: 247, Loss: 0.1478
Batch: 248, Loss: 0.1322
Batch: 249, Loss: 0.1689
Batch: 250, Loss: 0.1811
Batch: 251, Loss: 0.1681
Batch: 252, Loss: 0.2102
Batch: 253, Loss: 0.1879
Batch: 254, Loss: 0.1568
Batch: 255, Loss: 0.1794
Batch: 256, Loss: 0.1647
Batch: 257, Loss: 0.1244
Batch: 258, Loss: 0.1546
Batch: 259, Loss: 0.1801
Batch: 260, Loss: 0.1632
Batch: 261, Loss: 0.1664
Batch: 262, Loss: 0.1892
Batch: 263, Loss: 0.1822
Batch: 264, Loss: 0.1961
Batch: 265, Loss: 0.1597
Batch: 266, Loss: 0.1725
Batch: 267, Loss: 0.1409
Batch: 268, Loss: 0.1621
Batch: 269, Loss: 0.1626
Batch: 270, Loss: 0.1910
Batch: 271, Loss: 0.1845
Batch: 272, Loss: 0.1567
Batch: 273, Loss: 0.1559
Batch: 274, Loss: 0.1333
Batch: 275, Loss: 0.2519
Batch: 276, Loss: 0.1758
Batch: 277, Loss: 0.1865
Batch: 278, Loss: 0.1667
Batch: 279, Loss: 0.1855
Batch: 280, Loss: 0.1559
Batch: 281, Loss: 0.1655
Batch: 282, Loss: 0.1502
Batch: 283, Loss: 0.1694
Batch: 284, Loss: 0.1943
Batch: 285, Loss: 0.1937
Batch: 286, Loss: 0.1939
Batch: 287, Loss: 0.1622
Batch: 288, Loss: 0.1526
Batch: 289, Loss: 0.1410
Batch: 290, Loss: 0.2212
Batch: 291, Loss: 0.1722
Batch: 292, Loss: 0.1507
Batch: 293, Loss: 0.1631
Batch: 294, Loss: 0.1436
Batch: 295, Loss: 0.1450
Batch: 296, Loss: 0.1716
Batch: 297, Loss: 0.1410
Batch: 298, Loss: 0.1568
Batch: 299, Loss: 0.1917
Batch: 300, Loss: 0.1547
Batch: 301, Loss: 0.1731
Batch: 302, Loss: 0.1410
Batch: 303, Loss: 0.1629
Batch: 304, Loss: 0.1852
Batch: 305, Loss: 0.1732
Batch: 306, Loss: 0.1903
Batch: 307, Loss: 0.1780
Batch: 308, Loss: 0.1759
Batch: 309, Loss: 0.1792
Batch: 310, Loss: 0.1645
Batch: 311, Loss: 0.1890
Batch: 312, Loss: 0.1413
Batch: 313, Loss: 0.1871
Batch: 314, Loss: 0.1802
Batch: 315, Loss: 0.1630
Batch: 316, Loss: 0.1951
Batch: 317, Loss: 0.2066
Batch: 318, Loss: 0.1547
Batch: 319, Loss: 0.2317
Batch: 320, Loss: 0.2052
Batch: 321, Loss: 0.1712
Batch: 322, Loss: 0.1620
Batch: 323, Loss: 0.1604
Batch: 324, Loss: 0.1312
Batch: 325, Loss: 0.1371
Batch: 326, Loss: 0.2320
Batch: 327, Loss: 0.1936
Batch: 328, Loss: 0.1658
Batch: 329, Loss: 0.1850
Batch: 330, Loss: 0.1516
Batch: 331, Loss: 0.1864
Batch: 332, Loss: 0.2070
Batch: 333, Loss: 0.1348
Batch: 334, Loss: 0.1717
Batch: 335, Loss: 0.1613
Batch: 336, Loss: 0.1858
Batch: 337, Loss: 0.1374
Batch: 338, Loss: 0.1967
Epoch 2/5 - Training Loss: 0.1788
Epoch 2/5, Train Loss: 0.1788, Validation Loss: 0.1644
Epoch 3/5
Batch: 1, Loss: 0.1802
Batch: 2, Loss: 0.1640
Batch: 3, Loss: 0.1833
Batch: 4, Loss: 0.1761
Batch: 5, Loss: 0.1059
Batch: 6, Loss: 0.2092
Batch: 7, Loss: 0.1350
Batch: 8, Loss: 0.1653
Batch: 9, Loss: 0.1560
Batch: 10, Loss: 0.1634
Batch: 11, Loss: 0.1671
Batch: 12, Loss: 0.1448
Batch: 13, Loss: 0.1566
Batch: 14, Loss: 0.1721
Batch: 15, Loss: 0.1706
Batch: 16, Loss: 0.1571
Batch: 17, Loss: 0.1699
Batch: 18, Loss: 0.1518
Batch: 19, Loss: 0.1629
Batch: 20, Loss: 0.2192
Batch: 21, Loss: 0.1543
Batch: 22, Loss: 0.1771
Batch: 23, Loss: 0.1312
Batch: 24, Loss: 0.1452
Batch: 25, Loss: 0.1685
Batch: 26, Loss: 0.1948
Batch: 27, Loss: 0.1403
Batch: 28, Loss: 0.1241
Batch: 29, Loss: 0.2012
Batch: 30, Loss: 0.1598
Batch: 31, Loss: 0.1543
Batch: 32, Loss: 0.1178
Batch: 33, Loss: 0.1445
Batch: 34, Loss: 0.1974
Batch: 35, Loss: 0.1349
Batch: 36, Loss: 0.1760
Batch: 37, Loss: 0.1620
Batch: 38, Loss: 0.1600
Batch: 39, Loss: 0.1815
Batch: 40, Loss: 0.1448
Batch: 41, Loss: 0.2012
Batch: 42, Loss: 0.1282
Batch: 43, Loss: 0.1255
Batch: 44, Loss: 0.1465
Batch: 45, Loss: 0.1825
Batch: 46, Loss: 0.1489
Batch: 47, Loss: 0.1297
Batch: 48, Loss: 0.1627
Batch: 49, Loss: 0.1598
Batch: 50, Loss: 0.1790
Batch: 51, Loss: 0.1821
Batch: 52, Loss: 0.1482
Batch: 53, Loss: 0.1726
Batch: 54, Loss: 0.1733
Batch: 55, Loss: 0.1594
Batch: 56, Loss: 0.1324
Batch: 57, Loss: 0.1532
Batch: 58, Loss: 0.1495
Batch: 59, Loss: 0.1494
Batch: 60, Loss: 0.1505
Batch: 61, Loss: 0.2097
Batch: 62, Loss: 0.1246
Batch: 63, Loss: 0.1696
Batch: 64, Loss: 0.1665
Batch: 65, Loss: 0.1674
Batch: 66, Loss: 0.1696
Batch: 67, Loss: 0.1677
Batch: 68, Loss: 0.1461
Batch: 69, Loss: 0.1276
Batch: 70, Loss: 0.1306
Batch: 71, Loss: 0.1921
Batch: 72, Loss: 0.1469
Batch: 73, Loss: 0.1444
Batch: 74, Loss: 0.1490
Batch: 75, Loss: 0.1586
Batch: 76, Loss: 0.1340
Batch: 77, Loss: 0.1589
Batch: 78, Loss: 0.1675
Batch: 79, Loss: 0.1242
Batch: 80, Loss: 0.1612
Batch: 81, Loss: 0.1252
Batch: 82, Loss: 0.1841
Batch: 83, Loss: 0.1930
Batch: 84, Loss: 0.1632
Batch: 85, Loss: 0.1588
Batch: 86, Loss: 0.1371
Batch: 87, Loss: 0.1451
Batch: 88, Loss: 0.1948
Batch: 89, Loss: 0.1571
Batch: 90, Loss: 0.1894
Batch: 91, Loss: 0.1858
Batch: 92, Loss: 0.1657
Batch: 93, Loss: 0.1338
Batch: 94, Loss: 0.1417
Batch: 95, Loss: 0.1475
Batch: 96, Loss: 0.1571
Batch: 97, Loss: 0.1694
Batch: 98, Loss: 0.1803
Batch: 99, Loss: 0.1727
Batch: 100, Loss: 0.1731
Batch: 101, Loss: 0.1724
Batch: 102, Loss: 0.1630
Batch: 103, Loss: 0.1772
Batch: 104, Loss: 0.1341
Batch: 105, Loss: 0.1821
Batch: 106, Loss: 0.1103
Batch: 107, Loss: 0.1779
Batch: 108, Loss: 0.1560
Batch: 109, Loss: 0.1744
Batch: 110, Loss: 0.2000
Batch: 111, Loss: 0.1555
Batch: 112, Loss: 0.1763
Batch: 113, Loss: 0.1949
Batch: 114, Loss: 0.1817
Batch: 115, Loss: 0.1850
Batch: 116, Loss: 0.1446
Batch: 117, Loss: 0.1911
Batch: 118, Loss: 0.1570
Batch: 119, Loss: 0.1310
Batch: 120, Loss: 0.1502
Batch: 121, Loss: 0.1448
Batch: 122, Loss: 0.1330
Batch: 123, Loss: 0.1495
Batch: 124, Loss: 0.1733
Batch: 125, Loss: 0.1652
Batch: 126, Loss: 0.1539
Batch: 127, Loss: 0.1611
Batch: 128, Loss: 0.1927
Batch: 129, Loss: 0.1355
Batch: 130, Loss: 0.1530
Batch: 131, Loss: 0.1661
Batch: 132, Loss: 0.1360
Batch: 133, Loss: 0.1904
Batch: 134, Loss: 0.1509
Batch: 135, Loss: 0.1640
Batch: 136, Loss: 0.2274
Batch: 137, Loss: 0.1607
Batch: 138, Loss: 0.1866
Batch: 139, Loss: 0.1689
Batch: 140, Loss: 0.1770
Batch: 141, Loss: 0.1181
Batch: 142, Loss: 0.1222
Batch: 143, Loss: 0.1760
Batch: 144, Loss: 0.2090
Batch: 145, Loss: 0.1757
Batch: 146, Loss: 0.1539
Batch: 147, Loss: 0.1553
Batch: 148, Loss: 0.1628
Batch: 149, Loss: 0.1467
Batch: 150, Loss: 0.1622
Batch: 151, Loss: 0.1740
Batch: 152, Loss: 0.1988
Batch: 153, Loss: 0.1800
Batch: 154, Loss: 0.1485
Batch: 155, Loss: 0.1526
Batch: 156, Loss: 0.1720
Batch: 157, Loss: 0.1589
Batch: 158, Loss: 0.1409
Batch: 159, Loss: 0.1848
Batch: 160, Loss: 0.1594
Batch: 161, Loss: 0.1760
Batch: 162, Loss: 0.1812
Batch: 163, Loss: 0.1635
Batch: 164, Loss: 0.1374
Batch: 165, Loss: 0.1492
Batch: 166, Loss: 0.1720
Batch: 167, Loss: 0.1590
Batch: 168, Loss: 0.1582
Batch: 169, Loss: 0.1583
Batch: 170, Loss: 0.1691
Batch: 171, Loss: 0.1443
Batch: 172, Loss: 0.1214
Batch: 173, Loss: 0.1708
Batch: 174, Loss: 0.1487
Batch: 175, Loss: 0.1957
Batch: 176, Loss: 0.1773
Batch: 177, Loss: 0.1347
Batch: 178, Loss: 0.1387
Batch: 179, Loss: 0.1637
Batch: 180, Loss: 0.1167
Batch: 181, Loss: 0.1340
Batch: 182, Loss: 0.1367
Batch: 183, Loss: 0.1757
Batch: 184, Loss: 0.1361
Batch: 185, Loss: 0.1606
Batch: 186, Loss: 0.1331
Batch: 187, Loss: 0.1298
Batch: 188, Loss: 0.1501
Batch: 189, Loss: 0.1243
Batch: 190, Loss: 0.1374
Batch: 191, Loss: 0.1690
Batch: 192, Loss: 0.1857
Batch: 193, Loss: 0.1541
Batch: 194, Loss: 0.1517
Batch: 195, Loss: 0.1462
Batch: 196, Loss: 0.1675
Batch: 197, Loss: 0.1592
Batch: 198, Loss: 0.1507
Batch: 199, Loss: 0.1878
Batch: 200, Loss: 0.1795
Batch: 201, Loss: 0.1561
Batch: 202, Loss: 0.1688
Batch: 203, Loss: 0.1551
Batch: 204, Loss: 0.1710
Batch: 205, Loss: 0.1350
Batch: 206, Loss: 0.1648
Batch: 207, Loss: 0.1462
Batch: 208, Loss: 0.1726
Batch: 209, Loss: 0.1613
Batch: 210, Loss: 0.1501
Batch: 211, Loss: 0.1587
Batch: 212, Loss: 0.1528
Batch: 213, Loss: 0.1508
Batch: 214, Loss: 0.1208
Batch: 215, Loss: 0.1818
Batch: 216, Loss: 0.1760
Batch: 217, Loss: 0.1397
Batch: 218, Loss: 0.1318
Batch: 219, Loss: 0.1731
Batch: 220, Loss: 0.1598
Batch: 221, Loss: 0.1487
Batch: 222, Loss: 0.1568
Batch: 223, Loss: 0.1766
Batch: 224, Loss: 0.1169
Batch: 225, Loss: 0.1510
Batch: 226, Loss: 0.1669
Batch: 227, Loss: 0.1426
Batch: 228, Loss: 0.1312
Batch: 229, Loss: 0.1218
Batch: 230, Loss: 0.1562
Batch: 231, Loss: 0.1370
Batch: 232, Loss: 0.1415
Batch: 233, Loss: 0.1401
Batch: 234, Loss: 0.1428
Batch: 235, Loss: 0.1505
Batch: 236, Loss: 0.1933
Batch: 237, Loss: 0.1169
Batch: 238, Loss: 0.1456
Batch: 239, Loss: 0.1505
Batch: 240, Loss: 0.1608
Batch: 241, Loss: 0.1839
Batch: 242, Loss: 0.1776
Batch: 243, Loss: 0.1164
Batch: 244, Loss: 0.1696
Batch: 245, Loss: 0.1636
Batch: 246, Loss: 0.1365
Batch: 247, Loss: 0.1374
Batch: 248, Loss: 0.2105
Batch: 249, Loss: 0.1681
Batch: 250, Loss: 0.1225
Batch: 251, Loss: 0.1222
Batch: 252, Loss: 0.1656
Batch: 253, Loss: 0.1439
Batch: 254, Loss: 0.1851
Batch: 255, Loss: 0.1232
Batch: 256, Loss: 0.1640
Batch: 257, Loss: 0.1781
Batch: 258, Loss: 0.1423
Batch: 259, Loss: 0.1262
Batch: 260, Loss: 0.1509
Batch: 261, Loss: 0.1716
Batch: 262, Loss: 0.1503
Batch: 263, Loss: 0.1522
Batch: 264, Loss: 0.1392
Batch: 265, Loss: 0.1980
Batch: 266, Loss: 0.1765
Batch: 267, Loss: 0.1300
Batch: 268, Loss: 0.1641
Batch: 269, Loss: 0.1385
Batch: 270, Loss: 0.1492
Batch: 271, Loss: 0.1194
Batch: 272, Loss: 0.1370
Batch: 273, Loss: 0.1980
Batch: 274, Loss: 0.1638
Batch: 275, Loss: 0.1223
Batch: 276, Loss: 0.1418
Batch: 277, Loss: 0.1463
Batch: 278, Loss: 0.1617
Batch: 279, Loss: 0.1373
Batch: 280, Loss: 0.1762
Batch: 281, Loss: 0.1597
Batch: 282, Loss: 0.1421
Batch: 283, Loss: 0.1614
Batch: 284, Loss: 0.1768
Batch: 285, Loss: 0.1379
Batch: 286, Loss: 0.1287
Batch: 287, Loss: 0.1764
Batch: 288, Loss: 0.1771
Batch: 289, Loss: 0.1357
Batch: 290, Loss: 0.1869
Batch: 291, Loss: 0.1297
Batch: 292, Loss: 0.1700
Batch: 293, Loss: 0.1235
Batch: 294, Loss: 0.1510
Batch: 295, Loss: 0.1998
Batch: 296, Loss: 0.1557
Batch: 297, Loss: 0.1997
Batch: 298, Loss: 0.1490
Batch: 299, Loss: 0.1584
Batch: 300, Loss: 0.1531
Batch: 301, Loss: 0.1405
Batch: 302, Loss: 0.1817
Batch: 303, Loss: 0.1534
Batch: 304, Loss: 0.1476
Batch: 305, Loss: 0.1543
Batch: 306, Loss: 0.1289
Batch: 307, Loss: 0.1712
Batch: 308, Loss: 0.1522
Batch: 309, Loss: 0.2139
Batch: 310, Loss: 0.1695
Batch: 311, Loss: 0.1951
Batch: 312, Loss: 0.1531
Batch: 313, Loss: 0.1674
Batch: 314, Loss: 0.2194
Batch: 315, Loss: 0.1685
Batch: 316, Loss: 0.1917
Batch: 317, Loss: 0.1631
Batch: 318, Loss: 0.1336
Batch: 319, Loss: 0.1852
Batch: 320, Loss: 0.1551
Batch: 321, Loss: 0.1402
Batch: 322, Loss: 0.1687
Batch: 323, Loss: 0.1436
Batch: 324, Loss: 0.1634
Batch: 325, Loss: 0.1288
Batch: 326, Loss: 0.1405
Batch: 327, Loss: 0.1347
Batch: 328, Loss: 0.1395
Batch: 329, Loss: 0.1756
Batch: 330, Loss: 0.1523
Batch: 331, Loss: 0.1780
Batch: 332, Loss: 0.1492
Batch: 333, Loss: 0.1527
Batch: 334, Loss: 0.1363
Batch: 335, Loss: 0.1364
Batch: 336, Loss: 0.1335
Batch: 337, Loss: 0.1605
Batch: 338, Loss: 0.1816
Epoch 3/5 - Training Loss: 0.1584
Epoch 3/5, Train Loss: 0.1584, Validation Loss: 0.1648
Epoch 4/5
Batch: 1, Loss: 0.1741
Batch: 2, Loss: 0.1486
Batch: 3, Loss: 0.2148
Batch: 4, Loss: 0.1604
Batch: 5, Loss: 0.1622
Batch: 6, Loss: 0.1470
Batch: 7, Loss: 0.1670
Batch: 8, Loss: 0.2018
Batch: 9, Loss: 0.1894
Batch: 10, Loss: 0.1939
Batch: 11, Loss: 0.1575
Batch: 12, Loss: 0.1825
Batch: 13, Loss: 0.1582
Batch: 14, Loss: 0.1529
Batch: 15, Loss: 0.1503
Batch: 16, Loss: 0.1932
Batch: 17, Loss: 0.1476
Batch: 18, Loss: 0.1335
Batch: 19, Loss: 0.1805
Batch: 20, Loss: 0.1757
Batch: 21, Loss: 0.1883
Batch: 22, Loss: 0.1999
Batch: 23, Loss: 0.1586
Batch: 24, Loss: 0.1650
Batch: 25, Loss: 0.1581
Batch: 26, Loss: 0.1336
Batch: 27, Loss: 0.2178
Batch: 28, Loss: 0.1710
Batch: 29, Loss: 0.1858
Batch: 30, Loss: 0.1486
Batch: 31, Loss: 0.1495
Batch: 32, Loss: 0.1336
Batch: 33, Loss: 0.1894
Batch: 34, Loss: 0.1540
Batch: 35, Loss: 0.1708
Batch: 36, Loss: 0.1628
Batch: 37, Loss: 0.1690
Batch: 38, Loss: 0.1617
Batch: 39, Loss: 0.1524
Batch: 40, Loss: 0.1411
Batch: 41, Loss: 0.1523
Batch: 42, Loss: 0.1184
Batch: 43, Loss: 0.1135
Batch: 44, Loss: 0.1226
Batch: 45, Loss: 0.1820
Batch: 46, Loss: 0.2065
Batch: 47, Loss: 0.1467
Batch: 48, Loss: 0.1685
Batch: 49, Loss: 0.1838
Batch: 50, Loss: 0.1819
Batch: 51, Loss: 0.1747
Batch: 52, Loss: 0.1275
Batch: 53, Loss: 0.1741
Batch: 54, Loss: 0.1662
Batch: 55, Loss: 0.1510
Batch: 56, Loss: 0.0969
Batch: 57, Loss: 0.1175
Batch: 58, Loss: 0.1660
Batch: 59, Loss: 0.1592
Batch: 60, Loss: 0.1380
Batch: 61, Loss: 0.1676
Batch: 62, Loss: 0.1505
Batch: 63, Loss: 0.1455
Batch: 64, Loss: 0.1443
Batch: 65, Loss: 0.1248
Batch: 66, Loss: 0.1312
Batch: 67, Loss: 0.1787
Batch: 68, Loss: 0.0929
Batch: 69, Loss: 0.1599
Batch: 70, Loss: 0.1076
Batch: 71, Loss: 0.1276
Batch: 72, Loss: 0.1679
Batch: 73, Loss: 0.1310
Batch: 74, Loss: 0.1501
Batch: 75, Loss: 0.1290
Batch: 76, Loss: 0.1336
Batch: 77, Loss: 0.1089
Batch: 78, Loss: 0.1301
Batch: 79, Loss: 0.1361
Batch: 80, Loss: 0.1040
Batch: 81, Loss: 0.1465
Batch: 82, Loss: 0.1725
Batch: 83, Loss: 0.1578
Batch: 84, Loss: 0.1917
Batch: 85, Loss: 0.1966
Batch: 86, Loss: 0.1200
Batch: 87, Loss: 0.1555
Batch: 88, Loss: 0.1811
Batch: 89, Loss: 0.1718
Batch: 90, Loss: 0.1503
Batch: 91, Loss: 0.1640
Batch: 92, Loss: 0.1307
Batch: 93, Loss: 0.1432
Batch: 94, Loss: 0.1404
Batch: 95, Loss: 0.1347
Batch: 96, Loss: 0.1453
Batch: 97, Loss: 0.1476
Batch: 98, Loss: 0.1610
Batch: 99, Loss: 0.1816
Batch: 100, Loss: 0.1476
Batch: 101, Loss: 0.1495
Batch: 102, Loss: 0.1445
Batch: 103, Loss: 0.1658
Batch: 104, Loss: 0.1667
Batch: 105, Loss: 0.1446
Batch: 106, Loss: 0.1120
Batch: 107, Loss: 0.1088
Batch: 108, Loss: 0.1777
Batch: 109, Loss: 0.1407
Batch: 110, Loss: 0.1199
Batch: 111, Loss: 0.1750
Batch: 112, Loss: 0.1539
Batch: 113, Loss: 0.1701
Batch: 114, Loss: 0.1697
Batch: 115, Loss: 0.1861
Batch: 116, Loss: 0.1737
Batch: 117, Loss: 0.1500
Batch: 118, Loss: 0.1652
Batch: 119, Loss: 0.1081
Batch: 120, Loss: 0.1726
Batch: 121, Loss: 0.1324
Batch: 122, Loss: 0.1338
Batch: 123, Loss: 0.1464
Batch: 124, Loss: 0.1544
Batch: 125, Loss: 0.2006
Batch: 126, Loss: 0.1655
Batch: 127, Loss: 0.1388
Batch: 128, Loss: 0.1623
Batch: 129, Loss: 0.1433
Batch: 130, Loss: 0.1098
Batch: 131, Loss: 0.1481
Batch: 132, Loss: 0.1769
Batch: 133, Loss: 0.1343
Batch: 134, Loss: 0.1372
Batch: 135, Loss: 0.1620
Batch: 136, Loss: 0.1601
Batch: 137, Loss: 0.1857
Batch: 138, Loss: 0.1404
Batch: 139, Loss: 0.1328
Batch: 140, Loss: 0.1639
Batch: 141, Loss: 0.1510
Batch: 142, Loss: 0.1818
Batch: 143, Loss: 0.2151
Batch: 144, Loss: 0.1740
Batch: 145, Loss: 0.1817
Batch: 146, Loss: 0.1654
Batch: 147, Loss: 0.2073
Batch: 148, Loss: 0.1397
Batch: 149, Loss: 0.1598
Batch: 150, Loss: 0.1925
Batch: 151, Loss: 0.1733
Batch: 152, Loss: 0.1494
Batch: 153, Loss: 0.2014
Batch: 154, Loss: 0.1511
Batch: 155, Loss: 0.2387
Batch: 156, Loss: 0.1611
Batch: 157, Loss: 0.1428
Batch: 158, Loss: 0.1380
Batch: 159, Loss: 0.1575
Batch: 160, Loss: 0.1863
Batch: 161, Loss: 0.1407
Batch: 162, Loss: 0.1563
Batch: 163, Loss: 0.1222
Batch: 164, Loss: 0.2025
Batch: 165, Loss: 0.1687
Batch: 166, Loss: 0.1632
Batch: 167, Loss: 0.1667
Batch: 168, Loss: 0.1308
Batch: 169, Loss: 0.1622
Batch: 170, Loss: 0.1462
Batch: 171, Loss: 0.1585
Batch: 172, Loss: 0.1781
Batch: 173, Loss: 0.1610
Batch: 174, Loss: 0.1791
Batch: 175, Loss: 0.1187
Batch: 176, Loss: 0.1505
Batch: 177, Loss: 0.1568
Batch: 178, Loss: 0.1316
Batch: 179, Loss: 0.1668
Batch: 180, Loss: 0.1532
Batch: 181, Loss: 0.1697
Batch: 182, Loss: 0.1529
Batch: 183, Loss: 0.1485
Batch: 184, Loss: 0.1365
Batch: 185, Loss: 0.1837
Batch: 186, Loss: 0.1152
Batch: 187, Loss: 0.1333
Batch: 188, Loss: 0.1490
Batch: 189, Loss: 0.1795
Batch: 190, Loss: 0.1588
Batch: 191, Loss: 0.1578
Batch: 192, Loss: 0.1448
Batch: 193, Loss: 0.1388
Batch: 194, Loss: 0.1422
Batch: 195, Loss: 0.1783
Batch: 196, Loss: 0.1466
Batch: 197, Loss: 0.1904
Batch: 198, Loss: 0.1133
Batch: 199, Loss: 0.1360
Batch: 200, Loss: 0.1428
Batch: 201, Loss: 0.1351
Batch: 202, Loss: 0.0979
Batch: 203, Loss: 0.1353
Batch: 204, Loss: 0.1499
Batch: 205, Loss: 0.1499
Batch: 206, Loss: 0.1622
Batch: 207, Loss: 0.1161
Batch: 208, Loss: 0.1930
Batch: 209, Loss: 0.1652
Batch: 210, Loss: 0.1661
Batch: 211, Loss: 0.1738
Batch: 212, Loss: 0.1300
Batch: 213, Loss: 0.1131
Batch: 214, Loss: 0.1457
Batch: 215, Loss: 0.1486
Batch: 216, Loss: 0.1685
Batch: 217, Loss: 0.2067
Batch: 218, Loss: 0.2100
Batch: 219, Loss: 0.1243
Batch: 220, Loss: 0.1618
Batch: 221, Loss: 0.1598
Batch: 222, Loss: 0.1451
Batch: 223, Loss: 0.1577
Batch: 224, Loss: 0.1405
Batch: 225, Loss: 0.1423
Batch: 226, Loss: 0.1648
Batch: 227, Loss: 0.1082
Batch: 228, Loss: 0.1315
Batch: 229, Loss: 0.1721
Batch: 230, Loss: 0.1775
Batch: 231, Loss: 0.1623
Batch: 232, Loss: 0.1822
Batch: 233, Loss: 0.1629
Batch: 234, Loss: 0.1429
Batch: 235, Loss: 0.1710
Batch: 236, Loss: 0.1131
Batch: 237, Loss: 0.1574
Batch: 238, Loss: 0.1097
Batch: 239, Loss: 0.1760
Batch: 240, Loss: 0.1387
Batch: 241, Loss: 0.1164
Batch: 242, Loss: 0.1359
Batch: 243, Loss: 0.1522
Batch: 244, Loss: 0.1339
Batch: 245, Loss: 0.1277
Batch: 246, Loss: 0.1270
Batch: 247, Loss: 0.1616
Batch: 248, Loss: 0.1287
Batch: 249, Loss: 0.1494
Batch: 250, Loss: 0.1795
Batch: 251, Loss: 0.1587
Batch: 252, Loss: 0.1078
Batch: 253, Loss: 0.1901
Batch: 254, Loss: 0.1299
Batch: 255, Loss: 0.1583
Batch: 256, Loss: 0.1660
Batch: 257, Loss: 0.1675
Batch: 258, Loss: 0.1529
Batch: 259, Loss: 0.2288
Batch: 260, Loss: 0.0876
Batch: 261, Loss: 0.1464
Batch: 262, Loss: 0.1713
Batch: 263, Loss: 0.1356
Batch: 264, Loss: 0.1294
Batch: 265, Loss: 0.1473
Batch: 266, Loss: 0.1599
Batch: 267, Loss: 0.1232
Batch: 268, Loss: 0.1415
Batch: 269, Loss: 0.1364
Batch: 270, Loss: 0.1880
Batch: 271, Loss: 0.1660
Batch: 272, Loss: 0.1253
Batch: 273, Loss: 0.1667
Batch: 274, Loss: 0.1297
Batch: 275, Loss: 0.1339
Batch: 276, Loss: 0.1373
Batch: 277, Loss: 0.1421
Batch: 278, Loss: 0.1438
Batch: 279, Loss: 0.1801
Batch: 280, Loss: 0.1342
Batch: 281, Loss: 0.1587
Batch: 282, Loss: 0.1296
Batch: 283, Loss: 0.1359
Batch: 284, Loss: 0.1606
Batch: 285, Loss: 0.1308
Batch: 286, Loss: 0.1287
Batch: 287, Loss: 0.1042
Batch: 288, Loss: 0.1612
Batch: 289, Loss: 0.1480
Batch: 290, Loss: 0.1548
Batch: 291, Loss: 0.1395
Batch: 292, Loss: 0.1792
Batch: 293, Loss: 0.1627
Batch: 294, Loss: 0.1398
Batch: 295, Loss: 0.1531
Batch: 296, Loss: 0.1542
Batch: 297, Loss: 0.1245
Batch: 298, Loss: 0.1529
Batch: 299, Loss: 0.1397
Batch: 300, Loss: 0.1629
Batch: 301, Loss: 0.1571
Batch: 302, Loss: 0.1372
Batch: 303, Loss: 0.1446
Batch: 304, Loss: 0.1537
Batch: 305, Loss: 0.1536
Batch: 306, Loss: 0.1387
Batch: 307, Loss: 0.1495
Batch: 308, Loss: 0.1394
Batch: 309, Loss: 0.1746
Batch: 310, Loss: 0.1712
Batch: 311, Loss: 0.1575
Batch: 312, Loss: 0.1652
Batch: 313, Loss: 0.1461
Batch: 314, Loss: 0.1834
Batch: 315, Loss: 0.1344
Batch: 316, Loss: 0.1747
Batch: 317, Loss: 0.1667
Batch: 318, Loss: 0.1261
Batch: 319, Loss: 0.2135
Batch: 320, Loss: 0.1866
Batch: 321, Loss: 0.2226
Batch: 322, Loss: 0.1374
Batch: 323, Loss: 0.1201
Batch: 324, Loss: 0.1654
Batch: 325, Loss: 0.1761
Batch: 326, Loss: 0.1609
Batch: 327, Loss: 0.1264
Batch: 328, Loss: 0.1476
Batch: 329, Loss: 0.1960
Batch: 330, Loss: 0.1312
Batch: 331, Loss: 0.1694
Batch: 332, Loss: 0.1810
Batch: 333, Loss: 0.1622
Batch: 334, Loss: 0.1397
Batch: 335, Loss: 0.1594
Batch: 336, Loss: 0.1599
Batch: 337, Loss: 0.1584
Batch: 338, Loss: 0.2006
Epoch 4/5 - Training Loss: 0.1546
Epoch 4/5, Train Loss: 0.1546, Validation Loss: 0.1323
Epoch 5/5
Batch: 1, Loss: 0.1228
Batch: 2, Loss: 0.1655
Batch: 3, Loss: 0.1372
Batch: 4, Loss: 0.1335
Batch: 5, Loss: 0.1344
Batch: 6, Loss: 0.0956
Batch: 7, Loss: 0.1537
Batch: 8, Loss: 0.1578
Batch: 9, Loss: 0.1650
Batch: 10, Loss: 0.1606
Batch: 11, Loss: 0.1498
Batch: 12, Loss: 0.1633
Batch: 13, Loss: 0.1334
Batch: 14, Loss: 0.1301
Batch: 15, Loss: 0.1448
Batch: 16, Loss: 0.1784
Batch: 17, Loss: 0.1346
Batch: 18, Loss: 0.1637
Batch: 19, Loss: 0.1493
Batch: 20, Loss: 0.2128
Batch: 21, Loss: 0.1606
Batch: 22, Loss: 0.1245
Batch: 23, Loss: 0.1855
Batch: 24, Loss: 0.1746
Batch: 25, Loss: 0.1410
Batch: 26, Loss: 0.1823
Batch: 27, Loss: 0.1738
Batch: 28, Loss: 0.1330
Batch: 29, Loss: 0.1559
Batch: 30, Loss: 0.1402
Batch: 31, Loss: 0.1513
Batch: 32, Loss: 0.1672
Batch: 33, Loss: 0.1685
Batch: 34, Loss: 0.1649
Batch: 35, Loss: 0.1880
Batch: 36, Loss: 0.1325
Batch: 37, Loss: 0.1489
Batch: 38, Loss: 0.1385
Batch: 39, Loss: 0.1428
Batch: 40, Loss: 0.1918
Batch: 41, Loss: 0.1058
Batch: 42, Loss: 0.1503
Batch: 43, Loss: 0.1800
Batch: 44, Loss: 0.1822
Batch: 45, Loss: 0.1179
Batch: 46, Loss: 0.1190
Batch: 47, Loss: 0.1553
Batch: 48, Loss: 0.1428
Batch: 49, Loss: 0.1400
Batch: 50, Loss: 0.1631
Batch: 51, Loss: 0.1424
Batch: 52, Loss: 0.1138
Batch: 53, Loss: 0.1515
Batch: 54, Loss: 0.1181
Batch: 55, Loss: 0.1469
Batch: 56, Loss: 0.1865
Batch: 57, Loss: 0.1545
Batch: 58, Loss: 0.1734
Batch: 59, Loss: 0.1389
Batch: 60, Loss: 0.1261
Batch: 61, Loss: 0.1354
Batch: 62, Loss: 0.1668
Batch: 63, Loss: 0.1025
Batch: 64, Loss: 0.1353
Batch: 65, Loss: 0.1461
Batch: 66, Loss: 0.1488
Batch: 67, Loss: 0.1286
Batch: 68, Loss: 0.1318
Batch: 69, Loss: 0.1701
Batch: 70, Loss: 0.1288
Batch: 71, Loss: 0.1594
Batch: 72, Loss: 0.1469
Batch: 73, Loss: 0.1928
Batch: 74, Loss: 0.1593
Batch: 75, Loss: 0.2158
Batch: 76, Loss: 0.1063
Batch: 77, Loss: 0.1385
Batch: 78, Loss: 0.1356
Batch: 79, Loss: 0.1421
Batch: 80, Loss: 0.1037
Batch: 81, Loss: 0.1265
Batch: 82, Loss: 0.1578
Batch: 83, Loss: 0.1140
Batch: 84, Loss: 0.1481
Batch: 85, Loss: 0.1162
Batch: 86, Loss: 0.1185
Batch: 87, Loss: 0.1728
Batch: 88, Loss: 0.1626
Batch: 89, Loss: 0.1488
Batch: 90, Loss: 0.1627
Batch: 91, Loss: 0.2201
Batch: 92, Loss: 0.1382
Batch: 93, Loss: 0.1569
Batch: 94, Loss: 0.1675
Batch: 95, Loss: 0.1442
Batch: 96, Loss: 0.1500
Batch: 97, Loss: 0.1600
Batch: 98, Loss: 0.1498
Batch: 99, Loss: 0.1518
Batch: 100, Loss: 0.1709
Batch: 101, Loss: 0.1591
Batch: 102, Loss: 0.1399
Batch: 103, Loss: 0.1518
Batch: 104, Loss: 0.1609
Batch: 105, Loss: 0.1217
Batch: 106, Loss: 0.1445
Batch: 107, Loss: 0.1812
Batch: 108, Loss: 0.1799
Batch: 109, Loss: 0.1586
Batch: 110, Loss: 0.1631
Batch: 111, Loss: 0.1973
Batch: 112, Loss: 0.1540
Batch: 113, Loss: 0.1473
Batch: 114, Loss: 0.1589
Batch: 115, Loss: 0.1446
Batch: 116, Loss: 0.1217
Batch: 117, Loss: 0.1803
Batch: 118, Loss: 0.1801
Batch: 119, Loss: 0.1400
Batch: 120, Loss: 0.1566
Batch: 121, Loss: 0.1580
Batch: 122, Loss: 0.1250
Batch: 123, Loss: 0.1354
Batch: 124, Loss: 0.1705
Batch: 125, Loss: 0.1433
Batch: 126, Loss: 0.1267
Batch: 127, Loss: 0.1383
Batch: 128, Loss: 0.1388
Batch: 129, Loss: 0.1574
Batch: 130, Loss: 0.1623
Batch: 131, Loss: 0.1491
Batch: 132, Loss: 0.1401
Batch: 133, Loss: 0.1596
Batch: 134, Loss: 0.1367
Batch: 135, Loss: 0.1617
Batch: 136, Loss: 0.1450
Batch: 137, Loss: 0.1611
Batch: 138, Loss: 0.1722
Batch: 139, Loss: 0.1743
Batch: 140, Loss: 0.1323
Batch: 141, Loss: 0.1443
Batch: 142, Loss: 0.1486
Batch: 143, Loss: 0.1577
Batch: 144, Loss: 0.1374
Batch: 145, Loss: 0.1447
Batch: 146, Loss: 0.1395
Batch: 147, Loss: 0.1557
Batch: 148, Loss: 0.1449
Batch: 149, Loss: 0.1745
Batch: 150, Loss: 0.1885
Batch: 151, Loss: 0.1239
Batch: 152, Loss: 0.1706
Batch: 153, Loss: 0.1713
Batch: 154, Loss: 0.1592
Batch: 155, Loss: 0.1156
Batch: 156, Loss: 0.1155
Batch: 157, Loss: 0.1160
Batch: 158, Loss: 0.1664
Batch: 159, Loss: 0.1652
Batch: 160, Loss: 0.1597
Batch: 161, Loss: 0.1394
Batch: 162, Loss: 0.1882
Batch: 163, Loss: 0.1469
Batch: 164, Loss: 0.1435
Batch: 165, Loss: 0.1481
Batch: 166, Loss: 0.1398
Batch: 167, Loss: 0.2000
Batch: 168, Loss: 0.1028
Batch: 169, Loss: 0.1392
Batch: 170, Loss: 0.1192
Batch: 171, Loss: 0.1471
Batch: 172, Loss: 0.1443
Batch: 173, Loss: 0.1691
Batch: 174, Loss: 0.1498
Batch: 175, Loss: 0.1573
Batch: 176, Loss: 0.1515
Batch: 177, Loss: 0.1462
Batch: 178, Loss: 0.1993
Batch: 179, Loss: 0.1842
Batch: 180, Loss: 0.0915
Batch: 181, Loss: 0.1709
Batch: 182, Loss: 0.1556
Batch: 183, Loss: 0.1174
Batch: 184, Loss: 0.2086
Batch: 185, Loss: 0.1404
Batch: 186, Loss: 0.1128
Batch: 187, Loss: 0.1252
Batch: 188, Loss: 0.1262
Batch: 189, Loss: 0.1781
Batch: 190, Loss: 0.1613
Batch: 191, Loss: 0.1562
Batch: 192, Loss: 0.1409
Batch: 193, Loss: 0.1237
Batch: 194, Loss: 0.1394
Batch: 195, Loss: 0.1501
Batch: 196, Loss: 0.2074
Batch: 197, Loss: 0.1467
Batch: 198, Loss: 0.1612
Batch: 199, Loss: 0.1513
Batch: 200, Loss: 0.1122
Batch: 201, Loss: 0.0940
Batch: 202, Loss: 0.1329
Batch: 203, Loss: 0.1510
Batch: 204, Loss: 0.2058
Batch: 205, Loss: 0.1197
Batch: 206, Loss: 0.1323
Batch: 207, Loss: 0.1083
Batch: 208, Loss: 0.1293
Batch: 209, Loss: 0.1501
Batch: 210, Loss: 0.1602
Batch: 211, Loss: 0.1375
Batch: 212, Loss: 0.1426
Batch: 213, Loss: 0.1354
Batch: 214, Loss: 0.1148
Batch: 215, Loss: 0.1722
Batch: 216, Loss: 0.1409
Batch: 217, Loss: 0.1200
Batch: 218, Loss: 0.1713
Batch: 219, Loss: 0.1861
Batch: 220, Loss: 0.1508
Batch: 221, Loss: 0.1167
Batch: 222, Loss: 0.1177
Batch: 223, Loss: 0.1496
Batch: 224, Loss: 0.1148
Batch: 225, Loss: 0.1411
Batch: 226, Loss: 0.1683
Batch: 227, Loss: 0.1837
Batch: 228, Loss: 0.1356
Batch: 229, Loss: 0.1469
Batch: 230, Loss: 0.1636
Batch: 231, Loss: 0.1896
Batch: 232, Loss: 0.1584
Batch: 233, Loss: 0.1371
Batch: 234, Loss: 0.1670
Batch: 235, Loss: 0.1816
Batch: 236, Loss: 0.1291
Batch: 237, Loss: 0.1736
Batch: 238, Loss: 0.1633
Batch: 239, Loss: 0.1693
Batch: 240, Loss: 0.1267
Batch: 241, Loss: 0.1608
Batch: 242, Loss: 0.1225
Batch: 243, Loss: 0.1570
Batch: 244, Loss: 0.0868
Batch: 245, Loss: 0.1883
Batch: 246, Loss: 0.1381
Batch: 247, Loss: 0.1878
Batch: 248, Loss: 0.0942
Batch: 249, Loss: 0.1475
Batch: 250, Loss: 0.1455
Batch: 251, Loss: 0.1389
Batch: 252, Loss: 0.1480
Batch: 253, Loss: 0.1230
Batch: 254, Loss: 0.1483
Batch: 255, Loss: 0.1297
Batch: 256, Loss: 0.1217
Batch: 257, Loss: 0.1040
Batch: 258, Loss: 0.1237
Batch: 259, Loss: 0.1099
Batch: 260, Loss: 0.1117
Batch: 261, Loss: 0.1487
Batch: 262, Loss: 0.1246
Batch: 263, Loss: 0.1304
Batch: 264, Loss: 0.1144
Batch: 265, Loss: 0.1627
Batch: 266, Loss: 0.1652
Batch: 267, Loss: 0.1601
Batch: 268, Loss: 0.1405
Batch: 269, Loss: 0.1876
Batch: 270, Loss: 0.1822
Batch: 271, Loss: 0.1308
Batch: 272, Loss: 0.1227
Batch: 273, Loss: 0.1625
Batch: 274, Loss: 0.1482
Batch: 275, Loss: 0.1559
Batch: 276, Loss: 0.1355
Batch: 277, Loss: 0.1519
Batch: 278, Loss: 0.1552
Batch: 279, Loss: 0.1458
Batch: 280, Loss: 0.1478
Batch: 281, Loss: 0.1395
Batch: 282, Loss: 0.1653
Batch: 283, Loss: 0.1345
Batch: 284, Loss: 0.1407
Batch: 285, Loss: 0.1597
Batch: 286, Loss: 0.1766
Batch: 287, Loss: 0.1482
Batch: 288, Loss: 0.1691
Batch: 289, Loss: 0.1460
Batch: 290, Loss: 0.1377
Batch: 291, Loss: 0.1653
Batch: 292, Loss: 0.1455
Batch: 293, Loss: 0.1318
Batch: 294, Loss: 0.1297
Batch: 295, Loss: 0.1297
Batch: 296, Loss: 0.1136
Batch: 297, Loss: 0.1512
Batch: 298, Loss: 0.1648
Batch: 299, Loss: 0.1450
Batch: 300, Loss: 0.1322
Batch: 301, Loss: 0.1404
Batch: 302, Loss: 0.1231
Batch: 303, Loss: 0.1517
Batch: 304, Loss: 0.1428
Batch: 305, Loss: 0.1336
Batch: 306, Loss: 0.1618
Batch: 307, Loss: 0.1365
Batch: 308, Loss: 0.1213
Batch: 309, Loss: 0.1027
Batch: 310, Loss: 0.1255
Batch: 311, Loss: 0.2010
Batch: 312, Loss: 0.1241
Batch: 313, Loss: 0.1607
Batch: 314, Loss: 0.1272
Batch: 315, Loss: 0.1745
Batch: 316, Loss: 0.1344
Batch: 317, Loss: 0.1502
Batch: 318, Loss: 0.1107
Batch: 319, Loss: 0.1605
Batch: 320, Loss: 0.1353
Batch: 321, Loss: 0.1271
Batch: 322, Loss: 0.1667
Batch: 323, Loss: 0.1421
Batch: 324, Loss: 0.1459
Batch: 325, Loss: 0.1563
Batch: 326, Loss: 0.1851
Batch: 327, Loss: 0.1374
Batch: 328, Loss: 0.1591
Batch: 329, Loss: 0.1336
Batch: 330, Loss: 0.1618
Batch: 331, Loss: 0.1482
Batch: 332, Loss: 0.1659
Batch: 333, Loss: 0.1392
Batch: 334, Loss: 0.1193
Batch: 335, Loss: 0.1419
Batch: 336, Loss: 0.1667
Batch: 337, Loss: 0.1118
Batch: 338, Loss: 0.1598
Epoch 5/5 - Training Loss: 0.1482
Epoch 5/5, Train Loss: 0.1482, Validation Loss: 0.1262

Validation Metrics for Class Forest:
  Average Precision: 93.47%
  Accuracy: 97.00%
Validation Metrics for Class River:
  Average Precision: 75.90%
  Accuracy: 94.52%
Validation Metrics for Class Highway:
  Average Precision: 62.03%
  Accuracy: 93.19%
Validation Metrics for Class AnnualCrop:
  Average Precision: 64.34%
  Accuracy: 92.33%
Validation Metrics for Class SeaLake:
  Average Precision: 96.16%
  Accuracy: 97.56%
Validation Metrics for Class HerbaceousVegetation:
  Average Precision: 93.36%
  Accuracy: 97.00%
Validation Metrics for Class Industrial:
  Average Precision: 95.36%
  Accuracy: 97.56%
Validation Metrics for Class Residential:
  Average Precision: 85.84%
  Accuracy: 94.52%
Validation Metrics for Class PermanentCrop:
  Average Precision: 64.22%
  Accuracy: 92.37%
Validation Metrics for Class Pasture:
  Average Precision: 59.86%
  Accuracy: 94.37%
Mean Average Precision (mAP) on Test Set: 79.05%
Mean Accuracy over All Classes on Test Set: 95.04%

Test Metrics for Class Forest:
  Average Precision: 93.09%
  Accuracy: 97.07%
Test Metrics for Class River:
  Average Precision: 74.51%
  Accuracy: 94.70%
Test Metrics for Class Highway:
  Average Precision: 62.10%
  Accuracy: 93.04%
Test Metrics for Class AnnualCrop:
  Average Precision: 68.15%
  Accuracy: 93.30%
Test Metrics for Class SeaLake:
  Average Precision: 94.60%
  Accuracy: 97.74%
Test Metrics for Class HerbaceousVegetation:
  Average Precision: 93.11%
  Accuracy: 97.07%
Test Metrics for Class Industrial:
  Average Precision: 97.51%
  Accuracy: 98.33%
Test Metrics for Class Residential:
  Average Precision: 90.16%
  Accuracy: 95.93%
Test Metrics for Class PermanentCrop:
  Average Precision: 68.55%
  Accuracy: 93.37%
Test Metrics for Class Pasture:
  Average Precision: 59.63%
  Accuracy: 94.00%
Mean Average Precision (mAP) on Test Set: 80.14%
Mean Accuracy over All Classes on Test Set: 95.46%